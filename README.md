# PA-REAT
this is PA-REAT office code

# 1.Architecture
we propose a novel Pyramid Attention U-Net architecture for feature extraction, which generates initial salient objects. We then build a Residuals Efficient Channel Attention Transformer network (RECA-Transformer) to refine the edge details, ultimately achieving comprehensive boundary-aware prediction of salient objects.
![最终CNN(1)](https://github.com/user-attachments/assets/7ab9da11-6cd2-4b21-8aa4-49a040b8ebaf)

# 2.our result
![image](https://github.com/user-attachments/assets/cc13d07a-e33c-437e-8771-c8cb6adbc4e7)

# 3.Performance of competing methods
![image](https://github.com/user-attachments/assets/7c2aef54-8d2e-47e1-ae46-687c52303340)

# 4.Evaluation
[Evaluation Code](https://github.com/NathanUA/Binary-Segmentation-Evaluation-Tool)

