# PA-REAT
this is PA-REAT office code

# 1.Architecture
we propose a novel Pyramid Attention U-Net architecture for feature extraction, which generates initial salient objects. We then build a Residuals Efficient Channel Attention Transformer network (RECA-Transformer) to refine the edge details, ultimately achieving comprehensive boundary-aware prediction of salient objects.

![最终CNN(1)](https://github.com/user-attachments/assets/c3823cc2-29e2-457b-982e-3fdd51bbf4f3)


# 2.our result
![image](https://github.com/user-attachments/assets/cc13d07a-e33c-437e-8771-c8cb6adbc4e7)

# 3.Performance of competing methods
![image](https://github.com/user-attachments/assets/7c2aef54-8d2e-47e1-ae46-687c52303340)

# 4.Evaluation
[Evaluation Code](https://github.com/NathanUA/Binary-Segmentation-Evaluation-Tool)

